{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac85186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data procesing\n",
    "TRAIN_DIR = './imgs/train'\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=30,\n",
    "        zoom_range=0.3,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2, rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,  (224, 224),\n",
    "    subset='training'\n",
    "    \n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR, (224, 224),\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4cfe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=\"avg\")\n",
    "\n",
    "out1 = Dropout(0.5)(vgg_model.output)\n",
    "out1 = Dense(512, activation=\"relu\")(out1)\n",
    "\n",
    "out2 = Dense(10, activation=\"softmax\")(out1)\n",
    "\n",
    "vggmodel3 = Model(inputs=vgg_model.input, outputs=out2)\n",
    "ad= SGD(lr=0.002)\n",
    "\n",
    "vggmodel3.compile(loss='categorical_crossentropy', optimizer=ad, metrics=['accuracy'])\n",
    "\n",
    "print(vggmodel3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a822cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # \n",
    "hist = vggmodel3.fit_generator(generator=train_generator, epochs=7, validation_data=val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f16771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'],color='r')\n",
    "plt.plot(hist.history['val_loss'],color='g')\n",
    "plt.plot(hist.history['acc'],color='b')\n",
    "plt.plot(hist.history['val_acc'],color='k')\n",
    "plt.title('model loss and acc')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec903fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data procesing\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_path = './imgs/test/img_42.jpg'\n",
    "img = image.load_img(img_path,target_size=(224, 224))\n",
    "res = image.img_to_array(img)\n",
    "res = np.expand_dims(res, axis=0)\n",
    "res = preprocess_input(res)\n",
    "preds = vggmodel3.predict(res)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "hist = xception1.fit_generator(generator=train_generator, epochs=1, validation_data=val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction part\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "img_path = './imgs/test/img_189.jpg'\n",
    "img = image.load_img(img_path,target_size=(224, 224))\n",
    "res = image.img_to_array(img)\n",
    "res = np.expand_dims(res, axis=0)\n",
    "res = preprocess_input(res)\n",
    "preds = xception1.predict(res)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaad1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "TRAIN_DIR = './imgs/train'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        validation_split=0.3, rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,  (224, 224), batch_size=20,\n",
    "    subset='training'\n",
    "    \n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR, (224, 224),batch_size=20,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "xceptionbase = Xception(weights='imagenet', include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None)\n",
    "out1 = Flatten()(xceptionbase.output)\n",
    "out1 = Dropout(0.5)(out1)\n",
    "out1 = Dense(30, activation='relu')(out1)\n",
    "out2 = Dense(10, activation=\"softmax\")(out1)\n",
    "\n",
    "xception1 = Model(inputs=xceptionbase.input, outputs=out2)\n",
    "ad= SGD(lr=0.001,decay=1e-6, momentum=0.9)\n",
    "\n",
    "\n",
    "xception1.compile(loss='categorical_crossentropy', optimizer=ad, metrics=['accuracy'])\n",
    "\n",
    "print(xception1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43806d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose gpu 0 and train model\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "hist = xception1.fit_generator(generator=train_generator, epochs=1, validation_data=val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction part\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "img_path = './imgs/test/img_189.jpg'\n",
    "img = image.load_img(img_path,target_size=(224, 224))\n",
    "res = image.img_to_array(img)\n",
    "res = np.expand_dims(res, axis=0)\n",
    "res = preprocess_input(res)\n",
    "preds = xception1.predict(res)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg with no augmentation start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42cba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data and process\n",
    "TRAIN_DIR = './imgs/train'\n",
    "\n",
    "datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,(224, 224),\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,(224, 224),\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90875c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=\"max\")\n",
    "out1 = Dropout(0.5)(vgg_model.output)\n",
    "out2 = Dense(10, activation=\"softmax\")(out1)\n",
    "\n",
    "vgg_model2 = Model(inputs=vgg_model.input, outputs=out2)\n",
    "ad= SGD(lr=0.001)\n",
    "\n",
    "vgg_model2.compile(loss='categorical_crossentropy', optimizer=ad, metrics=['accuracy'])\n",
    "\n",
    "print(vgg_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # 使用 GPU 0\n",
    "hist = vgg_model2.fit_generator(generator=train_generator, epochs=4, validation_data=val_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot history\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'],color='r')\n",
    "plt.plot(hist.history['val_loss'],color='g')\n",
    "plt.plot(hist.history['accuracy'],color='b')\n",
    "plt.plot(hist.history['val_accuracy'],color='k')\n",
    "plt.title('model loss and acc')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'test_loss','train_acc', 'test_acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00153d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data procesing\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_path = './imgs/test/img_42.jpg'\n",
    "img = image.load_img(img_path,target_size=(224, 224))\n",
    "res = image.img_to_array(img)\n",
    "res = np.expand_dims(res, axis=0)\n",
    "res = preprocess_input(res)\n",
    "preds = vgg_model2.predict(res)\n",
    "print(preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
